---
title: "Week_8_EDA"
author: "Christopher Richards"
date: "May 1, 2019"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
options(warn=-1)
shhh <- suppressPackageStartupMessages # function to suprress install messages

shhh(library(tidyverse))
#install.packages("factoextra")
shhh(library(factoextra)) # cluster algorithims and visualizations
# rm(list = setdiff(ls(), "MyDF")) # Remove all but MyDF
```


<p></p>
<h3>Introduction</h3>
<p></p>

This file is my attempt at answering the questions in this week's assignment.  
  
  Three datasets were selected for analysis.  The data sets are:  
  New York Air Quality Measurements  
  Salaries for Professors  
  Violent Crime Rates by U.S. States

<p></p>
<h4>New York Air Quality Data set</h3><p></p>
<h4>1. Formulate your question</h4><p></p>
#### Question 1:  Is solar radiation affected by ozone density?  
  

  

<h4>2. Read in your data</h4>
I examined the data set in Notepad++ and noticed a number of NAs in the Ozone and Solar.R series.  Since these are the values of interest I have decided to omit them.  
The data set is read in, assigned and viewed.
```{r}
d_air <- read.csv("airquality.csv")

```

<h4>3. Check the packaging</h4>
The structure of the data set is examined.  First by row count, then by a count of columns.
```{r}
nrow(d_air)
ncol(d_air)
```



<h4>4. Run str()</h4>

```{r}
str(d_air)
```


<h4>5. Look at the top and the bottom of your data</h4>
```{r}
head(d_air)
tail(d_air)
```
<h4>6.Check for missing values</h4>
```{r}
summary(d_air)
```
 As noted after visually inspecting the data, there are Na's present in the Ozone and Solar.R.  I will remove them.
```{r}
d_air2 <- d_air[complete.cases(d_air),]
summary(d_air2)
```
 No Na's are found.  
 
 
<h4>7. Select relevant columns</h4>
```{r}
d_air3 <- d_air2 %>% select(Ozone, Solar.R)
summary(d_air3)
```

<h4>8. Visualize the data</h4>
Peng's checklist doesn't include this step here, but, I like to see the data earlier in the process.  
I'll perform some simple plots to see the distribution of the data.
```{r}
hist(d_air3$Ozone, breaks = 20)
hist(d_air3$Solar.R, breaks = 20)

```
<p></p>
The distribution of Ozone readings is heavily skewed with the majority of points at the low end of the scale.  Additionaly, there appears to be outliers above 150 parts per billion.  
  
  The distribution of solar radiation readings is less skewed although the highest frequency occurs around 240 Angstroms.  
<p></p>

<h4>9. Try the simple solution  </h4>
There are two simple approaches to answer the question of whether solar radiation is affected by ozone density.  One would be a simple scatter plot with a linear regression line to visualize any relationship between the two features.  The other solution would be to use a correlation plot to generate numeric values detailing the relationship.  I will use both here.

```{r}
gscat <- ggplot(d_air3, aes(x=d_air3$Ozone, y=d_air3$Solar.R)) +
  geom_point() +
  stat_smooth(method=lm) +
  xlab("Ozone") +
  ylab("Solar Radiation")
gscat
```

<p></p>
Here the regression line is trending upwards at an upward rate indicating a positive correlation between solar radiation and ozone.  As the density of ozone increases there is a measured increase in solar radiation measured.  
<p></p>
Let's use a correlation matrix next.

```{r}
cor(d_air3)
```
As we can see the correlation between the two is positive at .348 which confirms the interpretation of the regression model above.  
<p></p>


#### Question 2: Solar Radiation vs Month.  Cluster Analysis
In this section, I'll perform a cluster analysis of solar radiation by month.  

I'll create a dataframe of the desired features, solar radiationa nd month.  The distance between points in the dataframe will be calculated and passed to the clustering algorithim.
```{r}
dsrm <- data.frame(y=d_air2$Solar.R, x=d_air2$Month)
names(dsrm) <- c("Solar Radiation","Month")
dsrm
```

Scatterplot of months vs solar radiation
```{r}
plot(dsrm$`Solar Radiation`, dsrm$Month)
```



```{r}
dist.dsrm <- dist(dsrm)
```

```{r}
dsrm.clust <- hclust(dist.dsrm)
```
```{r}
plot(dsrm.clust)
```
<p></p>
The algorithim has clustered the data however the amount of data points and resulting clusters makes this difficult to read.  First, the clustering object will be converted to a dendrogram.  Next, I'll cut the dendrogram at various points to better visualize the results.
<p></p>
```{r}
hcd <- as.dendrogram(dsrm.clust)
par(mfrow=c(3,1))

plot(hcd, main="Main")
plot(cut(x=hcd, h=90)$upper, 
     main="Upper tree of cut at h=90")
plot(cut(hcd, h=90)$lower[[2]], 
     main="Second branch of lower tree with cut at h=90")
```

<p></p>
This result isn't very intuitive to me.  I'll try using kmeans to cluster the data.
### Determine Optimum Clusters
#### Average Sihouette Method
```{r}
fviz_nbclust(dsrm, FUNcluster = kmeans, method = "silhouette")
```

#### Elbow Chart
 
The best number of clusters will be at the point in the line where it bends to form an "elbow". 
```{r}
fviz_nbclust(dsrm, kmeans, method = "wss")
```
<p></p>
Both methods result in two as the optimal number of clusters.  I'll create a kmeans model of two clusters.
<p></p>
#### KMeans Cluster
```{r}
dsrm.kmeans <- kmeans(dsrm, centers = 2)
dsrm.kmeans
```
<p></p>
The resulting observations in each cluster are unbalanced with almost twice as many points in cluster 1 as in cluster 2.  Cluster 1 means are vastly larger then the means in Cluster 2.  This may be a result in the difference in numbers of points in each clusters.  More likely, though, the points in cluster 1 may simply be distributed across a larger area.  
  
  
  I'll plot the clusters to visualize the results.
  <p></p>
```{r}
dsrm.p <- fviz_cluster(dsrm.kmeans, geom = "point", data = dsrm) + ggtitle('k=2')
dsrm.p
```
  
<p></p>

#### Question 3: Ozone vs Month.  Cluster Analysis

```{r}
dom <- data.frame(y=d_air2$Ozone, x=d_air2$Month)
names(dom) <- c("Ozone","Month")
dom
```

Scatterplot of months vs ozone
```{r}
plot(dom$`Ozone`, dsrm$Month)
```



```{r}
dist.dom <- dist(dom)
```

```{r}
dom.clust <- hclust(dist.dom)
```
```{r}
plot(dom.clust)
```
<p></p>
The algorithim has clustered the data however the amount of data points and resulting clusters makes this difficult to read.  First, the clustering object will be converted to a dendrogram.  Next, I'll cut the dendrogram at various points to better visualize the results.
<p></p>
```{r}
hcd <- as.dendrogram(dom.clust)
par(mfrow=c(3,1))

plot(hcd, main="Main")
plot(cut(x=hcd, h=90)$upper, 
     main="Upper tree of cut at h=90")
plot(cut(hcd, h=90)$lower[[2]], 
     main="Second branch of lower tree with cut at h=90")
```

<p></p>
This result isn't very intuitive to me.  I'll try using kmeans to cluster the data.
### Determine Optimum Clusters
#### Average Sihouette Method
```{r}
fviz_nbclust(dom, FUNcluster = kmeans, method = "silhouette")
```

#### Elbow Chart
 
The best number of clusters will be at the point in the line where it bends to form an "elbow". 
```{r}
fviz_nbclust(dom, kmeans, method = "wss")
```
<p></p>
Both methods result in two as the optimal number of clusters.  I'll create a kmeans model of two clusters.
<p></p>
#### KMeans Cluster
```{r}
dom.kmeans <- kmeans(dom, centers = 2)
dom.kmeans
```
<p></p>
The resulting observations in each cluster are unbalanced again, although not as badly as the Solar Radiation vs Month clusters.  This may be a result in the difference in numbers of points in each clusters.  More likely, though, the points in cluster 1 may simply be distributed across a larger area.  
  
  
  I'll plot the clusters to visualize the results.
  <p></p>
```{r}
dom.p <- fviz_cluster(dom.kmeans, geom = "point", data = dom) + ggtitle('k=2')
dom.p
```
  
<p></p>
As we can see from the table of cluster means and the cluster plot, Cluster 1 encompasses a larger area then Cluster 2.  Clearly there are several points in Cluster 1 which account for this dispersion. 


<h4>Salaries for Professors Data set</h3><p></p>
<h4>1. Formulate your question</h4><p></p>
#### Question 1:  Do males achieve higher rank earlier in their professional careers then females?

<h4>2. Read in your data</h4>
```{r}
d.sal <- read.csv("Salaries.csv")
```

<h4>3. Check the packaging</h4>
The structure of the data set is examined.  First by row count, then by a count of columns.
```{r}
nrow(d.sal)
ncol(d.sal)
```



<h4>4. Run str()</h4>

```{r}
str(d.sal)
```


<h4>5. Look at the top and the bottom of your data</h4>
```{r}
head(d.sal)
tail(d.sal)
```
<h4>6.Check for missing values</h4>
```{r}
summary(d.sal)
```

Plot service yrs vs rank, grouped by sex
```{r}
gsal <- ggplot(data=d.sal, aes(x=d.sal$yrs.service, y=d.sal$rank)) + 
  geom_point() +
  facet_grid(sex~.) +
  geom_smooth(aes(line = d.sal$sex), method = lm) +
  xlab("Years of Service") +
  ylab("Rank")
gsal
```

Try a barchart: x is rank, y is avg yrs, bars by sex
```{r}
ggplot(d.sal, aes(x=factor(d.sal$rank),
                  y=d.sal$yrs.service,
                  fill = rank)) +
  stat_summary(fun.y="mean", geom="bar") +
  xlab("Rank") +
  ylab("Avg Yrs of Service") +
  facet_grid(sex~.)
```

In order to answer this question, I plotted the average years of service by sex for each rank.  
For Associate Professors the average years of service for each sex is fairly even with females having slightly fewer years of service.  Associate Professors are essentially even.  Full Professors show the most deviation between the sexes.  Males have over 22 years of service on average while females have fewer years.  Females have about 17 years of service.  
<p></p>
Based on the information available, I would say that our hypothesis, do males achieve higher rank earlier in their careers then females, to be false.  If it were true I would have expected males to have a lower average years of service for full Professor positions.  This chart shows the opposite of that.
<p></p>

<h4>1. Formulate your question</h4><p></p>
#### Question 2:  Does discipline make a difference in salary?
<p></p>
In this section, I will examine whether the choice of discipline makes a difference in salaries for professors.  
The provided data for the "discipline" feature is limited.  The levels are "A", theoretical disciplines, and "B", applied disciplines.  
<p></p>
Since our data is already read in I will proceed with a simple solution.  To answer the question I will find the average salary by discipline.  All data will be considered in the calculation
```{r}
mean.sal.disc <-  d.sal %>%
                  group_by(discipline) %>%
                  summarise(mean = mean(salary)) %>%
                  mutate_if(is.numeric, format, 0)
```
```{r}
ggplot(mean.sal.disc, aes(x = discipline, y = mean, fill = discipline)) +
         geom_bar(stat = "identity", width = .25) + 
         geom_text(aes(label=mean), vjust=1.5, color="black", size=3.5) +
         xlab("Discipline") +
         ylab("Average Salary") +
         annotate("text", x = 1.1, y=2.1, label = "$9,480.30 difference")
```


The average salary for applied disciplines, "B", is higher by $9480.30 then for theoretical, "A", disciplines.  This simple approach tells us that, in general, the discipline of the professor makes a difference in salary.  
<p></p>


<h4>1. Formulate your question</h4><p></p>
#### Question 3:  Which factor (discipline, sex, years of service) is more important in determining salary?
<p></p>
In this section, I will examine which factor has  the choice of discipline makes a difference in salaries for professors. 

corr matrix  
encode discipline, sex
```{r}

```

```{r}
pairs(~ salary + discipline + sex + yrs.service, data = d.sal)
```
```{r}
## put histograms on the diagonal
panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
## put (absolute) correlations on the upper panels,
## with size proportional to the correlations.
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    # text(0.5, 0.5, txt, cex = cex.cor * r) # This is the original from ?pairs()
    text(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2) # This is modified to soften font size changes
}
pairs(d.sal[, c(3,5,6,7)],  upper.panel = panel.cor,
                            diag.panel = panel.hist,
                            lower.panel = panel.smooth)


```
According to the correlation chart, Years of Service is the most important factor when determining salary.  The Years of Service correlation is .33, about twice as much as the other factors.




<h3>Violent Crime Rates by State Data set</h3><p></p>
<h4>1. Formulate your question</h4><p></p>
#### Question 1:  Which region is the most "murderous"?

<h4>2. Read in your data</h4>
```{r}
d.crime <- read.csv("USArrests.csv")
```

<h4>3. Check the packaging</h4>
The structure of the data set is examined.  First by row count, then by a count of columns.
```{r}
nrow(d.crime)
ncol(d.crime)
```



<h4>4. Run str()</h4>

```{r}
str(d.crime)
```


<h4>5. Look at the top and the bottom of your data</h4>
```{r}
head(d.crime)
tail(d.crime)
```
<h4>6.Check for missing values</h4>
```{r}
summary(d.crime)
```
 Data looks clean.  No Na's are found.  
 
 
<h4>7. Select relevant columns</h4>
I'll create a new dataframe of State and Murder observations.  State names are in the "X" column.  I'll rename it to "State".
```{r}
colnames(d.crime)[1] <- "State"
d.murder <- d.crime %>% select(State, Murder)
summary(d.murder)
```

<h4>8. Visualize the data</h4>
Murder Histogram
```{r}
hist(d.murder$Murder)
```

<h4>9. Try the simple solution.</h4>
<p></p>
I'm not sure how to do a cluster analysis for this data set.  The State feature is a factor that will not lend itself to clustering using kmeans, etc since it is unable to calculate a distance from a factor.  I could encode the states but the resulting encoded data would indicate an ordered relationship which is misleading.  
  
  Additionally, the question asks for finding the region with the most murders but there is no "region" variable in the data.  I will add a "region" feature using the data found at https://www.50states.com/city/regions.htm.  
<p></p>
I've created a list of states and their associated region.  I'll load that now.
```{r}
regions <- read.csv("us_states.csv")
head(regions)
```
Add the region column to the d.murder dataframe.
```{r}
d.murderreg <- d.murder %>% mutate(region = regions$region)
head(d.murderreg)
```

I'll group the data by region then determine the total murder for each region.
```{r}
mrdrgn <- d.murderreg  %>%
                  group_by(region) %>%
                  summarise("Total.Murders" = sum(Murder)) %>%
                  data.frame() %>% 
                  arrange(desc(Total.Murders))
mrdrgn
```

I'll show the result in a barplot
```{r}
ggplot(mrdrgn, aes(x = region, y = Total.Murders, fill = Total.Murders)) +
         geom_bar(stat = "identity", width = .25 ) + 
         geom_text(aes(label=Total.Murders), vjust=-1, color="black", size=3.5) +
         coord_flip() +
         scale_fill_gradient2(low='green', mid='snow3', high='red') +
         xlab("Region") +
         ylab("Total Murders") #+
        # annotate("text", x = 1, y=40, label = "Most Murderous Region is the Deep South")
```

The most murderous region in the United States is the Deep South.









#### Question 2:  Which region is rape most likely to occur?
<h4>7. Select relevant columns</h4>
I'll create a new dataframe of State and Murder observations.  State names are in the "X" column.  I'll rename it to "State".
```{r}
d.rape <- d.crime %>% select(State, Rape)
summary(d.rape)
```

Add Region column.
```{r}
d.rapereg <- d.rape %>% mutate(region = regions$region)
head(d.rapereg)
```


I'll group the data by region then determine the total murder for each region.
```{r}
rprgn <- d.rapereg  %>%
                  group_by(region) %>%
                  summarise("Total.Rapes" = sum(Rape)) %>%
                  data.frame() %>% 
                  arrange(desc(Total.Rapes))
rprgn
```

I'll show the result in a barplot
```{r}
ggplot(rprgn, aes(x = region, y = Total.Rapes, fill = Total.Rapes)) +
         geom_bar(stat = "identity", width = .25 ) + 
         geom_text(aes(label=Total.Rapes), vjust=-1, color="black", size=3.5) +
         coord_flip() +
         scale_fill_gradient2(low='green', mid='snow3', high='red') +
         xlab("Region") +
         ylab("Total Rapes") #+
        # annotate("text", x = 1, y=40, label = "Most Murderous Region is the Deep South")
```
The region a woman is most likely to be raped in is the Southwest with 170.7 rapes recorded.
<p></p>


#### Question 3. How does Population Desity affect all types of crimes?
<h4>7. Try the simple solution</h4>
In this case, I will plot scatterplots with regression lines of all types of crime against Population Density.
```
```{r}
mrdr.pop <- ggplot(d.crime, aes(x=d.crime$UrbanPop, y=d.crime$Murder)) +
  geom_point() +
  geom_smooth(method = lm) +
  xlab("Urban Population") +
  ylab("Murder")
mrdr.pop
```
```{r}
aslt.pop <- ggplot(d.crime, aes(x=d.crime$UrbanPop, y=d.crime$Assault)) +
  geom_point() +
  geom_smooth(method = lm) +
  xlab("Urban Population") +
  ylab("Assault")
aslt.pop
```
```{r}
rape.pop <- ggplot(d.crime, aes(x=d.crime$UrbanPop, y=d.crime$Rape)) +
  geom_point() +
  geom_smooth(method = lm) +
  xlab("Urban Population") +
  ylab("Rape")
rape.pop
```
It appears from the regression lines of the plots that all three categories of crime are positively affected by an increase in urban population density.  Judging by the slope of the lines, assault appears to be most affected as it increases the most when urban population increases.  Arrests for rape rises, as well, although not as rapidly.  Murder is the least affected, although it does show a small increase.  
<p></p>

<h3>Conclusion</h3>
This assignment was very challenging.  I feel I learned a lot by working through the analyses as well as I could.  Unfortunately, it's not clear if my approaches to the questions were appropriate.  I found this assignement frustrating because of that uncertainty and would have benefited from more direction in approaching the questions.  